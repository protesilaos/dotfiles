#!/bin/bash

    # This program is free software: you can redistribute it and/or modify
    # it under the terms of the GNU General Public License as published by
    # the Free Software Foundation, either version 3 of the License, or
    # (at your option) any later version.

    # This program is distributed in the hope that it will be useful,
    # but WITHOUT ANY WARRANTY; without even the implied warranty of
    # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    # GNU General Public License for more details.

    # You should have received a copy of the GNU General Public License
    # along with this program.  If not, see <http://www.gnu.org/licenses/>.

# Automation tool for running download commands by reading links from a file.
# Uses curl or youtube-dl depending on the file type's content.

# If input files are in the present working directory, the script will benefit from tab completion

# The file should contain links one per line.
# Files should be named by their content's file type and source website.
# [pics|vids]_[source].txt
# For example:
# pics_unsplash.txt will contain links to images on unsplash.com
# vids_youtube.txt will contain links to videos on youtube.com
# NOTE video files intended for audio extraction should be named `vids_aud_[source website].txt`

# TODO add functions/logic for podcasts
# TODO consider arbitrary web content (.html, .tar.gz ...)
# TODO additional functionality merits a dmenu wrapper

# general variables
# ============================
cli_path_to_links="$1"
list_of_links="$(cat $cli_path_to_links)"

# functions
# ============================

# the curl command to run on each link in the file
curl_loop ()
{
    local destination=$HOME/Downloads

    # enter the parent destination directory
    cd $destination

    # check if destination child dir exists, otherwise create it
    if [ ! -d $1 ]; then
        mkdir $destination/$1 && echo "Making directory for $1"
    fi

    # enter the child dir
    cd $1

    # run curl for each link
    for i in $list_of_links; do
        curl -O $i
    done
}

# run the curl loop depending on the file name
# this is to place the downloads in the appropriate location
get_images ()
{
    if [[ $cli_path_to_links = *'pexels'* ]]; then
        echo "Preparing downloads from pexels.com"
        curl_loop 'pexels'
    elif [[ $cli_path_to_links = *'unsplash'* ]]; then
        echo "Preparing downloads from unsplash.com"
        curl_loop 'unsplash'
    else
        echo "Preparing downloads for unsorted images"
        curl_loop 'unsorted'
	fi
}

# the youtube-dl command to run on each link in the file
youtubedl_loop ()
{
    if [[ $1 = 'audio' ]]; then
        for i in $list_of_links; do
            youtube-dl -cix --audio-format mp3 --yes-playlist "$i" -o "$HOME/Videos/youtube-dl/%(title)s.%(ext)s"
        done
    else
        for i in $list_of_links; do
            youtube-dl --no-playlist --no-part --write-description --newline --prefer-free-formats $i -o "$HOME/Videos/youtube-dl/%(title)s.%(ext)s"
        done
    fi
}

get_videos ()
{
    if [[ $cli_path_to_links = *'aud'* ]]; then
        echo "Preparing to extract audio from video files"
        youtubedl_loop 'audio'
    else
        echo "Preparing to download video files"
        youtubedl_loop
    fi
}

# # check if an item is in the defined array
# item_in_array ()
# {
    # local array=$2

    # for i in ${array[*]}
    # do
        # if [[ "$i" == "$1" ]]; then
            # return 0
        # fi
    # done
    # return 1
# }

# behaviour
# ============================
if [[ -f $cli_path_to_links ]]; then
    if [[ $cli_path_to_links = *'pics'* ]]; then
        get_images
    elif [[ $cli_path_to_links = *'vids'* ]]; then
        cli_path_to_links="$HOME/Desktop/vids_$1.txt"
        get_videos
    else
        echo "ERROR. Bad format: does not indicate content type. File should be ~/Desktop/[pics|vids][_|_aud_][source website].txt"
        echo "Examples: ~/Desktop/pics_unsplash.txt ; ~/Desktop/vids_youtube.txt ; ~/Desktop/vids_aud_youtube.txt"
    fi
else
    echo "No path to such file exists"
fi
